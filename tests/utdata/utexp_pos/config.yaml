retrieve_top_k: 10
rerank_top_k: 5
generation_top_k: 5
pyserini_num_threads: 4
run_name: null
dataset_folder: tests/dataset/test_tinyonly/
index_folder: tests/index/test_tinyonly/
runs_folder: tests/run/test_tinyonly/
experiments_folder: tests/exp/test_tinyonly
processing_num_proc: 40
overwrite_run: true
generator:
  init_args:
    _target_: models.generators.llm.LLM
    model_name: TinyLlama/TinyLlama-1.1B-Chat-v1.0
    max_new_tokens: 64
    max_length: 2048
    quantization: int4
    attn_implementation: sdpa
    batch_size: 1
dataset:
  train:
    doc:
      init_args:
        _target_: modules.dataset_processor.UT1Docs
        split: fake
    query:
      init_args:
        _target_: modules.dataset_processor.UT1Queries
        split: faketrain
  dev:
    doc:
      init_args:
        _target_: modules.dataset_processor.UT1Docs
        split: fake
    query:
      init_args:
        _target_: modules.dataset_processor.UT1Queries
        split: faketest
  test:
    doc:
      init_args:
        _target_: modules.dataset_processor.UT1Docs
        split: fake
    query:
      init_args:
        _target_: modules.dataset_processor.UT1Queries
        split: faketest
prompt:
  system: You are a helpful assistant. Your task is to extract relevant information
    from provided documents and to answer to questions as briefly as possible.
  user: f"Background:\n{docs}\n\nQuestion:\ {question}"
  system_without_docs: You are a helpful assistant. Answer the questions as briefly
    as possible.
  user_without_docs: f"Question:\ {question}"
