init_args: 
  _target_: models.generators.vllm.VLLM
  model_name: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
  max_new_tokens: 64
  max_length: 2048
  batch_size: 256
  gpu_memory_utilization: 0.2
